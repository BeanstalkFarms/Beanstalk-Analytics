{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065efec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "\n",
    "cur_path = os.path.abspath(\".\")\n",
    "if cur_path not in sys.path: \n",
    "    sys.path.append(cur_path)\n",
    "\n",
    "from functools import cache \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import altair as alt \n",
    "from altair import datum\n",
    "from subgrounds.subgrounds import Subgrounds, Subgraph\n",
    "from subgrounds.pagination import ShallowStrategy\n",
    "\n",
    "from utils.utils import ddf, load_subgraph, remove_prefix\n",
    "sg: Subgrounds\n",
    "bs: Subgraph\n",
    "sg, bs = load_subgraph()\n",
    "@cache \n",
    "def query_marketplace_fills(*args):\n",
    "    # Query historical farmer's market order and listing fills \n",
    "    q = bs.Query.podFills(first=10000)\n",
    "    df = sg.query_df(\n",
    "        [\n",
    "            q.amount, \n",
    "            q.index, \n",
    "            q.start, \n",
    "            # q.listing.status, \n",
    "            # q.order.status, \n",
    "            q.listing.pricePerPod, \n",
    "            q.order.pricePerPod, \n",
    "            q.transaction.timestamp, \n",
    "        ],\n",
    "        pagination_strategy=ShallowStrategy\n",
    "    )\n",
    "    df = remove_prefix(df, \"podFills_\")\n",
    "    return df \n",
    "    \n",
    "# history of all marketplace listing and order fills \n",
    "df_fills = query_marketplace_fills(1).copy()\n",
    "df_fills = df_fills.rename(columns={\n",
    "    \"listing_pricePerPod\": \"listing_price_per_pod\",\n",
    "    \"order_pricePerPod\": \"order_price_per_pod\", \n",
    "})\n",
    "df_fills.amount /= 10**6 \n",
    "df_fills['index'] /= 10**6 # Must use bracket notation for column name \"index\" to avoid clashing with dataframe index. \n",
    "df_fills.start /= 10**6\n",
    "df_fills['place_in_line'] = df_fills['index'] + df_fills.start\n",
    "df_fills.listing_price_per_pod = df_fills.listing_price_per_pod.fillna(0) / 1e6 \n",
    "df_fills.order_price_per_pod = df_fills.order_price_per_pod.fillna(0) / 1e6 \n",
    "df_fills['price_per_pod'] = df_fills.listing_price_per_pod + df_fills.order_price_per_pod\n",
    "df_fills[\"datetime\"] = pd.to_datetime(df_fills[\"transaction_timestamp\"], unit=\"s\")\n",
    "df_fills[\"date\"] = pd.to_datetime(df_fills[\"datetime\"].dt.date)\n",
    "df_fills = df_fills[[\n",
    "    \"date\", \"datetime\", \"amount\", \"index\", \n",
    "    \"start\", \"place_in_line\", \"price_per_pod\", \n",
    "]]\n",
    "df_fills.tail()\n",
    "# marketplace volume aggregated daily \n",
    "df_vol_daily = pd.DataFrame({\n",
    "    \"date\": pd.date_range(df_fills[\"date\"].min(), df_fills[\"date\"].max()), \n",
    "})\n",
    "num_dates = len(df_vol_daily)\n",
    "df_vol_daily = df_vol_daily.merge(\n",
    "    df_fills, how=\"left\", on=\"date\"\n",
    ").groupby(\"date\")[\"amount\"].sum().reset_index()\n",
    "assert len(df_vol_daily) == num_dates\n",
    "df_vol_daily = df_vol_daily.rename(columns=dict(amount=\"pod_volume\"))\n",
    "df_vol_daily.pod_volume = df_vol_daily.pod_volume.fillna(0)\n",
    "df_vol_daily.tail()\n",
    "\"\"\"\n",
    "Some notes: \n",
    "    ser why is vega-lite so hard ʕっ•ᴥ•ʔっ\n",
    "\n",
    "    Cross filtering by temporal domain through an interval selection: \n",
    "        In order to have the separate time axis perform cross filtering to the histogram and heatmap plots, it is necessary \n",
    "        that the encoding (brush uses encoding x, and in time axis, the encoding spec for x is date:T) that is used in the \n",
    "        plot housing the selection also exists and is of the same type within the cross filtered chart. This is why the detail \n",
    "        encoding of the heatmap uses this same value. See the following github link for reference. \n",
    "        https://stackoverflow.com/questions/71249346/use-interval-selection-from-one-dataset-chart-to-filter-data-in-another-dataset\n",
    "        Also it's a bit strange but if this encoding is made ordinal (i.e. date:O in the time axis x encoding) then the inclusion \n",
    "        of the detail encoding in the heatmap is not necessary. Tbh not sure why this is true but documenting nonetheless. \n",
    "        \n",
    "    Filtering by selection when the selection's mapped encoding is binned:\n",
    "        In this case, make sure not to use condition's for encodings as they don't accurately reflect binning. This could be rectified \n",
    "        with an explicit bin transform. See this issue: \n",
    "        https://stackoverflow.com/questions/60994128/how-to-click-on-square-of-heatmap-to-filter-linked-bar-chart-altair\n",
    "\"\"\"\n",
    "\n",
    "width = 750\n",
    "sel_point = alt.selection_single(encodings=['x'], nearest=True, on=\"mouseover\", clear=\"mouseout\", empty=\"none\")\n",
    "sel_brush = alt.selection_interval(encodings=['x'])\n",
    "\n",
    "base = alt.Chart(df_fills[['amount', 'place_in_line', 'price_per_pod', 'date']]\n",
    ").transform_filter(sel_brush)\n",
    "\n",
    "xbin = alt.Bin(extent=[df_fills.place_in_line.min(), df_fills.place_in_line.max()], maxbins=50)\n",
    "\n",
    "histogram_place_in_line = base.mark_rect(\n",
    ").encode(\n",
    "    x=alt.X(\"place_in_line:Q\", bin=xbin, axis=None), \n",
    "    y=alt.Y(\"sum(amount):Q\", axis=alt.Axis(title=\"Bin Volume (Pods)\")), \n",
    "    tooltip=alt.Tooltip(\"sum(amount)\", format=\",d\"),\n",
    ").properties(width=width, height=100)\n",
    "\n",
    "heatmap_base = base.properties(width=width, height=250)\n",
    "heatmap = heatmap_base.mark_rect(\n",
    ").encode(\n",
    "    x=alt.X(\"place_in_line:Q\", bin=xbin), \n",
    "    y=alt.Y(\n",
    "        \"price_per_pod:Q\", \n",
    "        scale=alt.Scale(domain=(0,1)), \n",
    "        bin=alt.Bin(extent=[0,1], step=.1), \n",
    "        axis=alt.Axis(title=\"Price Per Pod ($)\")\n",
    "    ), \n",
    "    color=alt.Color(\"sum(amount)\", scale=alt.Scale(type=\"log\", scheme=\"plasma\")), \n",
    "    detail='date:T',\n",
    "    tooltip=alt.Tooltip(\"sum(amount)\", format=\",d\",)\n",
    ")\n",
    "\n",
    "yield_curve_base = heatmap_base.encode(\n",
    "    x=alt.X(\"place_in_line:Q\", bin=xbin), \n",
    "    y=alt.Y(\"mean(price_per_pod)\"), \n",
    "    color=alt.value(\"#03dbfc\"),\n",
    ")\n",
    "yield_curve_point_size = alt.Size(\"sum(amount)\", scale=alt.Scale(range=[5, 125]))\n",
    "# scatter plot of yield curve \n",
    "yield_curve_points = yield_curve_base.mark_point(\n",
    ").encode(\n",
    "    size=yield_curve_point_size,\n",
    "    tooltip=alt.Tooltip(\"mean(price_per_pod)\")\n",
    ").add_selection(sel_point)\n",
    "# single mark for currently selected point (to visually highlight selection) \n",
    "yield_curve_point_selected = yield_curve_base.mark_point(filled=True\n",
    ").encode(size=yield_curve_point_size\n",
    ").transform_filter(sel_point)\n",
    "# single mark showing value of currently selected point\n",
    "yield_curve_text = yield_curve_base.mark_text(dy=-15, fontSize=15, stroke=\"black\", strokeWidth=.4\n",
    ").encode(\n",
    "    text=alt.Text('mean(price_per_pod):Q', format='.2f')\n",
    ").transform_filter(sel_point)\n",
    "\n",
    "time_axis = alt.Chart(df_vol_daily\n",
    ").mark_bar(\n",
    ").encode(\n",
    "    x=alt.X('date:T', axis=alt.Axis(title=\"Date\", format=\"%b %Y\", tickCount=8)), \n",
    "    y=alt.Y('pod_volume:Q', axis=alt.Axis(title=\"Farmer's Market Total Volume (Pods)\")), \n",
    ").properties(width=width, height=100\n",
    ").add_selection(sel_brush)\n",
    "\n",
    "c = alt.vconcat(\n",
    "    histogram_place_in_line, \n",
    "    alt.layer(heatmap, yield_curve_points, yield_curve_point_selected, yield_curve_text), \n",
    "    bounds=\"flush\"\n",
    ") & time_axis\n",
    "#c.save(\"../schemas/farmers_market_history.json\")\n",
    "c\n",
    "\n",
    "snaps = bs.Query.podMarketplaceDailySnapshots(first=10000, orderBy=\"season\", orderDirection='asc')\n",
    "bs.PodMarketplaceDailySnapshot.total_bean_vol = bs.PodMarketplaceDailySnapshot.totalBeanVolume / 1e6\n",
    "bs.PodMarketplaceDailySnapshot.total_pod_vol = bs.PodMarketplaceDailySnapshot.totalPodVolume / 1e6\n",
    "bs.PodMarketplaceDailySnapshot.total_pod_listing_vol = bs.PodMarketplaceDailySnapshot.totalPodsFilled / 1e6\n",
    "bs.PodMarketplaceDailySnapshot.total_pod_order_vol = bs.PodMarketplaceDailySnapshot.totalOrdersFilled / 1e6\n",
    "df_snaps_raw = sg.query_df([\n",
    "    snaps.timestamp, \n",
    "    snaps.season, \n",
    "    snaps.total_bean_vol, # total bean volume for filled orders / listings \n",
    "    snaps.total_pod_vol, # total pod volume for filled orders / listings \n",
    "    snaps.total_pod_listing_vol, # total pod volume for filled listings \n",
    "    snaps.total_pod_order_vol, # total pod volume for filled orders\n",
    "], pagination_strategy=ShallowStrategy)\n",
    "df_snaps_raw = remove_prefix(df_snaps_raw, 'podMarketplaceDailySnapshots_')\n",
    "df_snaps = df_snaps_raw.copy()\n",
    "df_snaps['total bean vol'] = df_snaps['total_bean_vol']\n",
    "df_snaps['total pod listing vol'] = df_snaps['total_pod_listing_vol']\n",
    "df_snaps['total pod order vol'] = df_snaps['total_pod_order_vol']\n",
    "df_snaps['total pod vol'] = df_snaps['total_pod_vol']\n",
    "value_vars = [\n",
    "    'total_bean_vol', 'total_pod_vol', 'total_pod_listing_vol', 'total_pod_order_vol'\n",
    "]\n",
    "label_vars = [\n",
    "    'total bean vol', 'total pod listing vol', 'total pod order vol', 'total pod vol'\n",
    "] \n",
    "id_vars = ['timestamp', 'season'] + label_vars\n",
    "df_snaps = df_snaps.melt(id_vars=id_vars, value_vars=value_vars).sort_values(\"season\")\n",
    "rm_indices = []\n",
    "for v in value_vars: \n",
    "    rm_indices = rm_indices + list(\n",
    "        np.argwhere(\n",
    "            ((df_snaps.season == 6074) & (df_snaps.variable == v)).values\n",
    "        ).ravel()[:-1]\n",
    "    )\n",
    "df_snaps = df_snaps.iloc[[i for i in range(len(df_snaps)) if i not in rm_indices]]\n",
    "df_snaps = df_snaps.loc[df_snaps.season >= 4357]\n",
    "\n",
    "area = alt.Chart(df_snaps).transform_filter(\n",
    "    datum.variable != 'total_pod_vol'\n",
    ").transform_stack(\n",
    "    stack=\"value\", \n",
    "    as_=['value_1', 'value_2'], \n",
    "    groupby=['season'],\n",
    "    sort=[alt.SortField('variable', 'descending')]\n",
    ").mark_area(point='transparent').encode(\n",
    "    x=\"season:O\", \n",
    "    y=\"value_1:Q\", \n",
    "    y2=\"value_2:Q\", \n",
    "    color=\"variable:N\", \n",
    "    tooltip=[alt.Tooltip(f'{e}:Q', format=\",d\") for e in label_vars]\n",
    ").properties(width=700)\n",
    "\n",
    "line = alt.Chart(df_snaps).transform_filter(\n",
    "    datum.variable == 'total_pod_vol'\n",
    ").mark_line().encode(\n",
    "    x=\"season:O\", \n",
    "    y=\"value:Q\", \n",
    "    color=\"variable:N\", \n",
    ").properties(width=700)\n",
    "\n",
    "c = area + line\n",
    "#c.save('../schemas/field_breakdown.json')\n",
    "c\n",
    "df_snaps.tail(5)\n",
    "import json\n",
    "from IPython.display import JSON\n",
    "JSON(json.loads(c.to_json()))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
