{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd4437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "import json \n",
    "from pathlib import Path \n",
    "from functools import cache\n",
    "from itertools import product\n",
    "\n",
    "cur_path = os.path.abspath(\"../..\")\n",
    "if cur_path not in sys.path: \n",
    "    sys.path.append(cur_path)\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import altair as alt \n",
    "from altair import datum\n",
    "from subgrounds.subgrounds import Subgrounds, Subgraph\n",
    "from subgrounds.subgraph import SyntheticField\n",
    "from subgrounds.pagination import ShallowStrategy\n",
    "\n",
    "from utils_notebook.utils import ddf, remove_prefix, load_subgraph, remove_keys\n",
    "from utils_notebook.vega import condition_union, output_chart\n",
    "from utils_notebook.testing import validate_season_series\n",
    "from utils_notebook.constants import ADDR_BEANSTALK\n",
    "sg, bs = load_subgraph()\n",
    "@cache\n",
    "def query_rewards(refresh=None): \n",
    "    bs.Reward.fertilized_beans_daily = SyntheticField(\n",
    "        lambda toFertilizer: float(toFertilizer) / 1e6, \n",
    "        SyntheticField.FLOAT, \n",
    "        bs.Reward.toFertilizer\n",
    "    ) \n",
    "    q = bs.Query.rewards(orderBy=\"blockNumber\", orderDirection=\"asc\", first=10000)\n",
    "    df = sg.query_df(\n",
    "        [\n",
    "            q.season, \n",
    "            q.fertilized_beans_daily, \n",
    "        ], \n",
    "        pagination_strategy=ShallowStrategy\n",
    "    )\n",
    "    return remove_prefix(df, 'rewards_').sort_values('season')\n",
    "\n",
    "@cache \n",
    "def query_fertilizer_tokens(refresh=None): \n",
    "    bs.FertilizerToken.fert = bs.FertilizerToken.supply \n",
    "    bs.FertilizerToken.start_bpf = bs.FertilizerToken.startBpf / 1e6 \n",
    "    bs.FertilizerToken.end_bpf = SyntheticField(\n",
    "      lambda _id: float(_id) / 1e6, \n",
    "      SyntheticField.FLOAT,\n",
    "      bs.FertilizerToken.id, \n",
    "    )\n",
    "    ft = bs.Query.fertilizerTokens(\n",
    "        first=10000, \n",
    "        orderBy=\"humidity\", \n",
    "        orderDirection=\"desc\"\n",
    "    )\n",
    "    df = sg.query_df(\n",
    "        [\n",
    "            ft.season, \n",
    "            ft.fert, \n",
    "            ft.start_bpf, \n",
    "            ft.end_bpf, \n",
    "        ],\n",
    "        pagination_strategy=ShallowStrategy\n",
    "    )\n",
    "    return remove_prefix(df, \"fertilizerTokens_\")\n",
    "# fertilizer emissions (incomplete season axis, all seasons unique)\n",
    "df_rewards = query_rewards(refresh=5).copy()\n",
    "df_rewards = df_rewards[['season', 'fertilized_beans_daily']]\n",
    "validate_season_series(df_rewards, allow_missing=True)\n",
    "df_rewards.head()\n",
    "df_fert = query_fertilizer_tokens(refresh=5).copy()\n",
    "df_fert = df_fert.merge(df_rewards, how=\"outer\", on=\"season\").sort_values('season')\n",
    "df_fert['fertilized_beans_daily'] = df_fert.fertilized_beans_daily.fillna(0)\n",
    "df_fert['fertilized_beans_cumulative'] = df_fert.fertilized_beans_daily.cumsum()\n",
    "df_fert['unfertilized_beans_cumulative'] = ((df_fert.fert * df_fert.end_bpf).cumsum() - df_fert.fertilized_beans_cumulative).ffill()\n",
    "df_fert = df_fert[\n",
    "    ['season', 'fertilized_beans_cumulative', 'unfertilized_beans_cumulative']\n",
    "].groupby(\"season\").agg({\n",
    "    \"fertilized_beans_cumulative\": \"max\", \n",
    "    \"unfertilized_beans_cumulative\": \"max\"\n",
    "}).reset_index()\n",
    "validate_season_series(df_fert, allow_missing=True)\n",
    "df_fert.head()\n",
    "@cache \n",
    "def query_field(refresh=None) -> pd.DataFrame: \n",
    "    field_snaps = bs.Query.fieldDailySnapshots(\n",
    "        orderBy=\"season\", \n",
    "        orderDirection=\"asc\", \n",
    "        first=10000, \n",
    "        where={\"field\": ADDR_BEANSTALK}\n",
    "    )\n",
    "    df_field = sg.query_df(\n",
    "        [\n",
    "            field_snaps.season, \n",
    "            field_snaps.newHarvestedPods, \n",
    "            field_snaps.newHarvestablePods, \n",
    "            field_snaps.podIndex, \n",
    "        ], \n",
    "        pagination_strategy=ShallowStrategy\n",
    "    )\n",
    "    return df_field \n",
    "df_field = query_field(refresh=3).copy()\n",
    "df_field = remove_prefix(df_field, \"fieldDailySnapshots_\")\n",
    "df_field = df_field.sort_values(\"season\")\n",
    "df_field['pods_harvestable_daily'] = (df_field.newHarvestablePods / 10**6)\n",
    "df_field['pods_harvested_daily'] = df_field.newHarvestedPods / 10**6\n",
    "df_field = df_field.drop(columns=['newHarvestablePods', 'newHarvestedPods'])\n",
    "df_field = df_field.groupby('season').agg({\n",
    "    # handles edge case for season 6074 which occurred multiple times \n",
    "    \"pods_harvestable_daily\": \"sum\", \n",
    "    \"pods_harvested_daily\": \"sum\", \n",
    "    \"podIndex\": \"max\"\n",
    "}).reset_index()\n",
    "df_field['pods_issued_cumulative'] = df_field.podIndex / 10**6\n",
    "df_field['pods_issued_daily'] = df_field.pods_issued_cumulative - df_field.pods_issued_cumulative.shift(1).fillna(0)\n",
    "df_field['pods_harvestable_cumulative'] = df_field.pods_harvested_daily.cumsum() # TODO: factor in harvestable daily \n",
    "df_field = df_field.drop(columns=['podIndex'])\n",
    "validate_season_series(df_field, allow_missing=True)\n",
    "df_field.tail()\n",
    "def silo_emissions_pre_replant() -> pd.DataFrame: \n",
    "    \"\"\"Temporary solution to subgraph not having silo emissions pre-replant \n",
    "    \n",
    "    Data was downloaded from dune \n",
    "    \"\"\"\n",
    "    with Path(\"data/SupplyIncrease.json\").open('r') as f: \n",
    "        data = json.loads(f.read())\n",
    "    data = [remove_keys(d['data'], ['__typename']) for d in data]\n",
    "    df_supply_inc = pd.DataFrame(data)[['season', 'newSilo']]\n",
    "    return df_supply_inc\n",
    "\n",
    "@cache \n",
    "def query_silo(refresh=None) -> pd.DataFrame: \n",
    "    silo_snaps = bs.Query.siloDailySnapshots(\n",
    "        orderBy=\"season\", \n",
    "        orderDirection=\"asc\", \n",
    "        first=10000, \n",
    "        where={\"silo\": ADDR_BEANSTALK}\n",
    "    )\n",
    "    df = sg.query_df(\n",
    "        [\n",
    "            silo_snaps.season, \n",
    "            silo_snaps.dailyBeanMints, \n",
    "            # silo_snaps.totalBeanMints, # add back when subgraph includes historical data \n",
    "        ], \n",
    "        pagination_strategy=ShallowStrategy\n",
    "    )\n",
    "    return df \n",
    "# process post-replant silo data (subgraph)\n",
    "df_silo = query_silo(refresh=1).copy()\n",
    "df_silo = remove_prefix(df_silo, \"siloDailySnapshots_\")\n",
    "df_silo = df_silo.loc[df_silo.season != 5903] # Subgraph bug probably? \n",
    "assert df_silo.season.min() == 6074, \"If this fails, then subgraph was fixed to include historical data.\"\n",
    "df_silo = df_silo.rename(columns={\"dailyBeanMints\": \"silo_emissions_daily\"})\n",
    "# process pre-replant silo data (downloaded from dune)\n",
    "df_silo_old = silo_emissions_pre_replant()\n",
    "df_silo_old = df_silo_old.rename(columns={\"newSilo\": \"silo_emissions_daily\"})\n",
    "# Combine pre and post replant data (no seasons in common so outer join)\n",
    "df_silo = df_silo.merge(df_silo_old, how=\"outer\")\n",
    "assert set(df_silo.columns) == set(['season', 'silo_emissions_daily'])\n",
    "df_silo = df_silo.sort_values(\"season\")\n",
    "df_silo = df_silo.groupby('season').agg({\n",
    "    # handles edge case for season 6074 which occurred multiple times \n",
    "    \"silo_emissions_daily\": \"sum\", \n",
    "}).reset_index()\n",
    "df_silo['silo_emissions_daily'] /= 10**6\n",
    "df_silo['silo_emissions_cumulative'] = df_silo.silo_emissions_daily.cumsum()\n",
    "validate_season_series(df_silo, allow_missing=True)\n",
    "df_silo.head() \n",
    "@cache \n",
    "def query_seasons(refresh=None) -> pd.DataFrame: \n",
    "    seasons = bs.Query.seasons(\n",
    "        first=10000, orderBy=\"season\", orderDirection=\"asc\"\n",
    "    )\n",
    "    bs.Season.bean_supply = bs.Season.beans / 1e6\n",
    "    df = sg.query_df([\n",
    "        seasons.season, \n",
    "        seasons.timestamp, \n",
    "        seasons.bean_supply, \n",
    "    ], pagination_strategy=ShallowStrategy)\n",
    "    df = remove_prefix(df, 'seasons_')\n",
    "    return df \n",
    "df_szns = query_seasons(refresh=1)\n",
    "df_szns['timestamp'] = pd.to_datetime(df_szns.timestamp, unit='s')\n",
    "validate_season_series(df_szns, allow_missing=False)\n",
    "df_szns = df_szns.loc[df_szns.season >= 2] # timestamps are wrong for season 0 and 1 \n",
    "df_szns.head()\n",
    "# data pre-processing \n",
    "df = df_szns.merge(\n",
    "    df_fert, how='left', on='season'\n",
    ").merge(\n",
    "    df_field, how='left', on='season'\n",
    ").merge(\n",
    "    df_silo, how='left', on='season'\n",
    ")\n",
    "assert len(df) == len(df_szns)\n",
    "df = df.ffill().fillna(0) # Not technically correct but close enough \n",
    "df['total_debt'] = (\n",
    "    df.pods_issued_cumulative\n",
    "    + df.unfertilized_beans_cumulative\n",
    ") \n",
    "df['total_credit'] = (\n",
    "    df.fertilized_beans_cumulative\n",
    "    + df.silo_emissions_cumulative \n",
    "    + df.pods_harvestable_cumulative\n",
    ")\n",
    "df['debt_credit_ratio'] = df.total_debt / df.total_credit\n",
    "df['fertilizer_adjusted_pod_rate'] = df.total_debt / df.bean_supply \n",
    "metrics_credit = [\n",
    "    'silo_emissions_cumulative',\n",
    "    'pods_harvestable_cumulative',\n",
    "    'fertilized_beans_cumulative', \n",
    "]\n",
    "metrics_debt = [\n",
    "    'unfertilized_beans_cumulative', \n",
    "    'pods_issued_cumulative', \n",
    "]\n",
    "metrics_credit_debt_aggregate = [\n",
    "    'total_debt', \n",
    "    'total_credit', \n",
    "]\n",
    "metrics_meta = [\n",
    "    'debt_credit_ratio', \n",
    "    'fertilizer_adjusted_pod_rate', \n",
    "]\n",
    "metrics = metrics_credit + metrics_debt + metrics_credit_debt_aggregate + metrics_meta\n",
    "columns = ['timestamp'] + metrics \n",
    "df = df[columns]\n",
    "df = df.resample(\"W\", on=\"timestamp\").last().drop(columns=\"timestamp\").reset_index()\n",
    "df_mask = df.silo_emissions_cumulative.isna()\n",
    "timestamp_min = df.timestamp.values[0]\n",
    "timestamp_exploit = df[df_mask].timestamp.values[0]\n",
    "timestamp_replant = df[df_mask].timestamp.values[-1]\n",
    "df = df.dropna()\n",
    "source = df.melt(\n",
    "    id_vars=['timestamp'], \n",
    "    value_vars=metrics, \n",
    ").sort_values([\"timestamp\", \"variable\"]).reset_index(drop=True)\n",
    "print(len(source))\n",
    "source.head(10)\n",
    "# alt.data_transformers.disable_max_rows()\n",
    "\n",
    "\n",
    "brush = alt.selection_interval(name=\"brush\", encodings=['x'])\n",
    "dropdown = alt.binding_select(options=['ym', 'ymd'], name='Aggregation Level')\n",
    "selection = alt.selection_single(name=\"agglevel\", fields=['AggLevel'], bind=dropdown, init={\"AggLevel\": 'ymd'})\n",
    "selection_rule = alt.selection_single(\n",
    "    fields=['tstamp'], nearest=True, on='mouseover', empty='none', clear='mouseout'\n",
    ")\n",
    "colors = {\n",
    "    'fertilized_beans_cumulative': '#57cc99', # green   \n",
    "    'unfertilized_beans_cumulative': \"#eb7d34\", # orange \n",
    "    'pods_harvestable_cumulative': '#38a3a5', # mid blue \n",
    "    'silo_emissions_cumulative': '#22577a', # navy blue \n",
    "    'pods_issued_cumulative': 'rgba(255, 0, 0, 0.5)', # transparent red  \n",
    "    'total_debt': '#e56b6f', # pastel red \n",
    "    'total_credit': '#80ed99', # mint green \n",
    "    'debt_credit_ratio': '#ffc300', # gold \n",
    "    'fertilizer_adjusted_pod_rate': '#42f563' # green idk \n",
    "}\n",
    "format_decimal = \",d\"\n",
    "format_percent = \".2%\"\n",
    "tooltip_formats = {\n",
    "    'fertilized_beans_cumulative': format_decimal,\n",
    "    'unfertilized_beans_cumulative': format_decimal,\n",
    "    'pods_harvestable_cumulative': format_decimal,\n",
    "    'silo_emissions_cumulative': format_decimal,\n",
    "    'pods_issued_cumulative': format_decimal,\n",
    "    'total_debt': format_decimal,\n",
    "    'total_credit': format_decimal,\n",
    "    'debt_credit_ratio': format_percent, \n",
    "    'fertilizer_adjusted_pod_rate': format_percent,\n",
    "}\n",
    "assert set(colors.keys()) == set(metrics)\n",
    "assert set(tooltip_formats.keys()) == set(metrics)\n",
    "\n",
    "# ngl I popped off on this one \n",
    "stack_order_expr = (\n",
    "    # creates numeric stack order key encoding both x position and order of stacked area labels into single value \n",
    "    ' '.join(\n",
    "        [\n",
    "            f\"datum.variable === '{m}' ? {i} : \" \n",
    "            for i, m in enumerate(reversed(metrics))\n",
    "        ]\n",
    "    ) \n",
    "    + str(len(metrics))\n",
    ")\n",
    "stack_order_expr = f'time(datum.tstamp) + ({stack_order_expr})'\n",
    "\n",
    "base = alt.Chart(source).properties(\n",
    "    height=225, width=750\n",
    ").transform_filter(\n",
    "    brush \n",
    ").transform_timeunit(\n",
    "    ymd=\"yearmonthdate(timestamp)\", \n",
    "    ym=\"yearmonth(timestamp)\", \n",
    ").transform_calculate(\n",
    "    tstamp=\"datum[agglevel.AggLevel]\", \n",
    ").transform_aggregate(\n",
    "    groupby=[\"tstamp\", 'variable'], \n",
    "    rvalue='max(value)'\n",
    ").transform_calculate(\n",
    "    stack_order=stack_order_expr, \n",
    ").encode(\n",
    "    x=alt.X(\n",
    "        \"tstamp:O\", \n",
    "        axis=alt.Axis(\n",
    "            formatType=\"time\", \n",
    "            labelExpr=\"timeFormat(toDate(datum.value), '%Y-%m-%d')\", \n",
    "            labelOverlap=True, \n",
    "            labelSeparation=25, \n",
    "            title=None\n",
    "        ), \n",
    "    ),   \n",
    ")\n",
    "base_bdv = base.encode(\n",
    "    y=alt.Y(\"rvalue:Q\", axis=alt.Axis(title=\"Bean Denominated Value (BDV)\")),\n",
    "    color=alt.Color(\n",
    "        \"variable:N\", \n",
    "        scale=alt.Scale(\n",
    "            domain=metrics_credit + metrics_debt + metrics_credit_debt_aggregate, \n",
    "            range=[colors[m] for m in metrics_credit + metrics_debt + metrics_credit_debt_aggregate]\n",
    "        ),\n",
    "    ),\n",
    "    order=alt.Order('stack_order:Q', sort='ascending')\n",
    ")\n",
    "base_ratio = base.encode(\n",
    "    y=alt.Y(\"rvalue:Q\", axis=alt.Axis(title=\"Percent (%)\", format=\".2%\")),\n",
    "    color=alt.Color(\n",
    "        \"variable:N\", \n",
    "        scale=alt.Scale(\n",
    "            domain=metrics_meta, range=[colors[m] for m in metrics_meta]\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "rule = base.transform_pivot(\n",
    "    'variable', value='rvalue', groupby=['tstamp']\n",
    ").mark_rule(opacity=0).encode(\n",
    "    tooltip=[alt.Tooltip(f'{m}:Q', format=tooltip_formats[m]) for m in metrics] \n",
    ").add_selection(selection_rule)\n",
    "\n",
    "credit = base_bdv.mark_bar().transform_filter(\n",
    "    condition_union(\"==\", \"|\", metrics_credit)\n",
    ")\n",
    "debt = base_bdv.mark_bar().transform_filter(\n",
    "    condition_union(\"==\", \"|\", metrics_debt)\n",
    ")\n",
    "lines_debt_credit = base_bdv.mark_line().transform_filter(\n",
    "    condition_union('==', '|', metrics_credit_debt_aggregate)\n",
    ")\n",
    "line_ratio = base_ratio.mark_line().transform_filter(\n",
    "    condition_union('==', '|', metrics_meta)\n",
    ")\n",
    "\n",
    "time_axis = alt.Chart(\n",
    "    source[['timestamp']]\n",
    ").mark_bar(opacity=0).encode(\n",
    "    x='timestamp:T'\n",
    ")\n",
    "time_exploit_rect = alt.Chart(\n",
    "    pd.DataFrame([{\"timestamp_start\": timestamp_exploit, \"timestamp_end\": timestamp_replant}])\n",
    ").mark_rect().encode(\n",
    "    x=\"timestamp_start:T\", \n",
    "    x2=\"timestamp_end:T\",\n",
    "    color=alt.value('#4d4d4d')\n",
    ")\n",
    "# time_exploit_text = alt.Chart(\n",
    "#     pd.DataFrame([{\"timestamp\": timestamp_exploit + timestamp_replant}])\n",
    "# )\n",
    "\n",
    "c = (\n",
    "    alt.vconcat(\n",
    "        alt.layer(debt, credit, lines_debt_credit, rule).properties(title=\"Beanstalk Credit Breakdown\"),\n",
    "        line_ratio.properties(title=\"Beanstalk Credit Metrics\")\n",
    "    ).resolve_legend(\n",
    "        color=\"independent\", \n",
    "    ).resolve_axis(\n",
    "        y=\"independent\"\n",
    "    ).resolve_scale(\n",
    "        y=\"independent\", color=\"independent\"\n",
    "    ).add_selection(\n",
    "        selection,\n",
    "    ) \n",
    "    & alt.layer(\n",
    "        time_axis + time_exploit_rect\n",
    "    ).add_selection(\n",
    "        brush\n",
    "    ).properties(\n",
    "        height=75, width=750,\n",
    "    )\n",
    ")\n",
    "c\n",
    "output_chart(c)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
